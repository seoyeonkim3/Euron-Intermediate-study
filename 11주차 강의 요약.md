# 딥러닝 2단계: 심층 신경망 성능 향상시키기
## 5. 하이퍼파라미터 튜닝
### 5-1. 튜닝 프로세스(tuning process)
- 딥러닝에 존재하는 하이퍼파라미터(우선 조정하는 순서)
  - 학습률(α)
  - 모멘텀(Momentum) 알고리즘의 β
  - 은닉 유닛의 수
  - 미니배치 크기
  - 은닉층의 갯수
  - 학습률 감쇠(learning rate decay) 정도
  - 아담(Adam) 알고리즘의 $β_1$, $β_2$, ϵ

- 하이퍼파라미터의 탐색: 격자점x, 무작위 접근 방식으로 ∵ 어떤 하이퍼파라미터가 문제 해결에 더 중요한지 미리 알 수 x
  
- 정밀화 접근: 우선 전체 하이퍼파라미터 공간에서 탐색하여 좋은 점을 찾은 후, 그 근방에서 더 정밀하게 탐색하는 과정

### 5-2. 적절한 척도 선택하기(using an appropriate scale to pick hyperparameters)

무작위 ← 적절한 척도 정해서
- 무작위로 뽄는 것이 합리적인 하이퍼파라미터들 존재 ex) 은닉 유닛의 수($n^{[l]}$, 은닉층의 수(#layers)
- 학습률: 선형척도대신 로그척도에서 하이퍼파라미터를 찾는 것이 합리적
  
    r ∈ [a,b], $a=\log_{10}{(작은 값)}$, $b=\log_{10}{(큰 값)}$
  <br>
    $α=10^r$
- 지수 가중 이동 평균에서 사용되는 β: 1-β 취한 후, 로그척도에서 무작위 값을 선택하여 탐색
  
    r ∈ [a,b], $a=\log_{10}{(작은 값)}$, $b=\log_{10}{(큰 값)}$
  <br>
    $1-β=10^r$ → $β=1-10^r$
- 선형척도에서 샘플을 뽑은 것이 좋지 않은 이유: 1에 가까울 수록 알고리즘 결과에 더 큰 영향을 끼쳐서

### 5-3. 하이퍼파라미터 튜닝 실전(hyperparameters tuning in practice: Pandas vs Caviar)

하이퍼파라미터 찾을 때 사용하는 방법
1. 모델 돌보기(baby sitting one model) = 판다 접근
   - 하나의 모델로 매일 성능을 지켜보면서, 학습 속도를 조금 씩 바꾸는 방식
   - 컴퓨터의 자원이 많이 필요하지 않거나, 적은 숫자의 모델을 한번에 학습 시킬 수 있을 때 사용
2. 동시에 여러 모델 훈련(Training many models in parallel) = 캐비어 접근
   - 서로 다른 모델을 동시에 학습 후 마지막에 최고 성능을 보이는 것을 선택
   - 컴퓨터의 자원이 충분히 많아 여러 모델을 한번에 학습 시킬 수 있을 때 사용
